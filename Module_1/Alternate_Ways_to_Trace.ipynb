{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9f3949c-3ea7-4f23-ba3b-e3dfb659b11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\Hunar Bhatia\\OneDrive\\Desktop\\MAT_494_Langchain\\.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a22ea10-47d9-44de-bbab-136ccc964c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define Graph state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "\n",
    "# Define Nodes\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=formatted_docs, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "\n",
    "# Define Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_edge(START, \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25ea34b7-3b4b-495f-b33d-1c0944fab4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"How do I set up tracing if I'm using LangChain?\",\n",
       " 'messages': [HumanMessage(content=\"How do I set up tracing if I'm using LangChain?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='To set up tracing with LangChain, you need to install the necessary packages and configure your environment by setting a few environment variables. After that, you can log a trace and view it using the provided tools. For detailed instructions, refer to the Trace With LangChain guide.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1376, 'total_tokens': 1431, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CMy86MHXoE1CdIbXBwbLSWfNWZdNA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--627e36ae-3dc4-405d-ba88-95511ad50970-0', usage_metadata={'input_tokens': 1376, 'output_tokens': 55, 'total_tokens': 1431, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'documents': [Document(metadata={'id': '6a1433b1-c9ee-462c-82f3-cc4185550c19', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_opentelemetry', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_opentelemetry'}, page_content='Set up distributed tracing with LangChain\\u200b\\nTo enable distributed tracing across multiple services:'),\n",
       "  Document(metadata={'id': '6e5aa7cb-e0c4-4759-8d77-849a2a988bcf', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph'}, page_content='Trace with LangGraph - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsOverviewLangChainLangGraphAnthropic (Python only)OpenAIAutoGenClaude CodeCrewAIGoogle ADKInstructor (Python only)OpenAI Agents SDKOpenTelemetrySemantic KernelVercel AI SDKManual instrumentationConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationIntegrationsTrace with LangGraphGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageWith LangChain1. Installation2. Configure your environment3. Log a traceWithout LangChain1. Installation2. Configure your environment3. Log a traceTracing setupIntegrationsTrace with LangGraphCopy pageCopy pageLangSmith smoothly integrates with LangGraph (Python and JS) to help you trace agentic workflows, whether you’re using LangChain modules or other SDKs.\\n\\u200bWith LangChain\\nIf you are using LangChain modules within LangGraph, you only need to set a few environment variables to enable tracing.\\nThis guide will walk through a basic example. For more detailed information on configuration, see the Trace With LangChain guide.\\n\\u200b1. Installation'),\n",
       "  Document(metadata={'id': '10f42a74-5f62-470d-9435-8ed7ccdc0625', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides'}, page_content='Trace with LangChain (Python and JS/TS) - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsOverviewLangChainLangGraphAnthropic (Python only)OpenAIAutoGenClaude CodeCrewAIGoogle ADKInstructor (Python only)OpenAI Agents SDKOpenTelemetrySemantic KernelVercel AI SDKManual instrumentationConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationIntegrationsTrace with LangChain (Python and JS/TS)Get startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageInstallationQuick start1. Configure your environment2. Log a trace3. View your traceTrace selectivelyLog to a specific projectStaticallyDynamicallyAdd metadata and tags to tracesCustomize run nameCustomize run IDAccess run (span) ID for LangChain invocationsEnsure all traces are submitted before exitingTrace without setting environment variablesDistributed tracing with LangChain (Python)Interoperability between LangChain (Python) and LangSmith SDKInteroperability between LangChain.JS and LangSmith SDKTracing LangChain objects inside traceable (JS only)Tracing LangChain child runs via traceable / RunTree API (JS only)Tracing setupIntegrationsTrace with LangChain'),\n",
       "  Document(metadata={'id': 'fd04908f-5350-49b0-b7cb-0a455fa27393', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langchain', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langchain'}, page_content='Trace with LangChain (Python and JS/TS) - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsOverviewLangChainLangGraphAnthropic (Python only)OpenAIAutoGenClaude CodeCrewAIGoogle ADKInstructor (Python only)OpenAI Agents SDKOpenTelemetrySemantic KernelVercel AI SDKManual instrumentationConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationIntegrationsTrace with LangChain (Python and JS/TS)Get startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageInstallationQuick start1. Configure your environment2. Log a trace3. View your traceTrace selectivelyLog to a specific projectStaticallyDynamicallyAdd metadata and tags to tracesCustomize run nameCustomize run IDAccess run (span) ID for LangChain invocationsEnsure all traces are submitted before exitingTrace without setting environment variablesDistributed tracing with LangChain (Python)Interoperability between LangChain (Python) and LangSmith SDKInteroperability between LangChain.JS and LangSmith SDKTracing LangChain objects inside traceable (JS only)Tracing LangChain child runs via traceable / RunTree API (JS only)Tracing setupIntegrationsTrace with LangChain')]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I set up tracing if I'm using LangChain?\"\n",
    "simple_rag_graph.invoke({\"question\": question}, config={\"metadata\": {\"foo\": \"bar\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "834c0e3f-e6b6-47c8-9c27-cc5c05822e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully imported!\n",
      "RAG_PROMPT preview: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to ...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove the cached module\n",
    "if 'utils' in sys.modules:\n",
    "    del sys.modules['utils']\n",
    "\n",
    "# Now import fresh\n",
    "from utils import get_vector_db_retriever, RAG_PROMPT\n",
    "\n",
    "print(\"✓ Successfully imported!\")\n",
    "print(f\"RAG_PROMPT preview: {RAG_PROMPT[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52b04c32-c2ed-479a-9700-64354b51f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ utils.py has been updated!\n"
     ]
    }
   ],
   "source": [
    "# Write the correct content to utils.py\n",
    "utils_content = '''import os\n",
    "import tempfile\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the RAG prompt template\n",
    "RAG_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def get_vector_db_retriever():\n",
    "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "    embd = OpenAIEmbeddings()\n",
    "    \n",
    "    # If vector store exists, then load it\n",
    "    if os.path.exists(persist_path):\n",
    "        vectorstore = SKLearnVectorStore(\n",
    "            embedding=embd,\n",
    "            persist_path=persist_path,\n",
    "            serializer=\"parquet\"\n",
    "        )\n",
    "        return vectorstore.as_retriever(lambda_mult=0)\n",
    "    \n",
    "    # Otherwise, index LangSmith documents and create new vector store\n",
    "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
    "    ls_docs = ls_docs_sitemap_loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(ls_docs)\n",
    "    \n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=doc_splits,\n",
    "        embedding=embd,\n",
    "        persist_path=persist_path,\n",
    "        serializer=\"parquet\"\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore.as_retriever(lambda_mult=0)\n",
    "'''\n",
    "\n",
    "utils_path = r\"C:\\Users\\Hunar Bhatia\\OneDrive\\Desktop\\MAT_494_Langchain\\Module_1\\utils.py\"\n",
    "with open(utils_path, 'w') as f:\n",
    "    f.write(utils_content)\n",
    "    \n",
    "print(\"✓ utils.py has been updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e234c98f-5ba1-4c92-856a-eca0682dd257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ utils.py has been updated!\n",
      "✓ RAG_PROMPT found in utils.py\n",
      "\n",
      "--- File Contents ---\n",
      "import os\n",
      "import tempfile\n",
      "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
      "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
      "from langchain_community.vectorstores import SKLearnVectorStore\n",
      "from langchain_openai import OpenAIEmbeddings\n",
      "\n",
      "# Define the RAG prompt template\n",
      "RAG_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Question: {question}\n",
      "\n",
      "Context: {context}\n",
      "\n",
      "Answer:\"\"\"\n",
      "\n",
      "def get_vector_db_retriever():\n",
      "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
      "    embd = OpenAIEmbeddings()\n",
      "\n",
      "    # If vector store exists, then load it\n",
      "    if os.path.exists(persist_path):\n",
      "        vectorstore = SKLearnVectorStore(\n",
      "            embedding=embd,\n",
      "            persist_path=persist_path,\n",
      "            serializer=\"parquet\"\n",
      "        )\n",
      "        return vectorstore.as_retriever(lambda_mult=0)\n",
      "\n",
      "    # Otherwise, index LangSmith documents and create new vector store\n",
      "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
      "    ls_docs = ls_docs_sitemap_loader.load()\n",
      "\n",
      "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
      "        chunk_size=500, chunk_overlap=0\n",
      "    )\n",
      "    doc_splits = text_splitter.split_documents(ls_docs)\n",
      "\n",
      "    vectorstore = SKLearnVectorStore.from_documents(\n",
      "        documents=doc_splits,\n",
      "        embedding=embd,\n",
      "        persist_path=persist_path,\n",
      "        serializer=\"parquet\"\n",
      "    )\n",
      "    vectorstore.persist()\n",
      "    return vectorstore.as_retriever(lambda_mult=0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what's actually in utils.py# Write the correct content to utils.py\n",
    "utils_content = '''import os\n",
    "import tempfile\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the RAG prompt template\n",
    "RAG_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def get_vector_db_retriever():\n",
    "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "    embd = OpenAIEmbeddings()\n",
    "    \n",
    "    # If vector store exists, then load it\n",
    "    if os.path.exists(persist_path):\n",
    "        vectorstore = SKLearnVectorStore(\n",
    "            embedding=embd,\n",
    "            persist_path=persist_path,\n",
    "            serializer=\"parquet\"\n",
    "        )\n",
    "        return vectorstore.as_retriever(lambda_mult=0)\n",
    "    \n",
    "    # Otherwise, index LangSmith documents and create new vector store\n",
    "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
    "    ls_docs = ls_docs_sitemap_loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(ls_docs)\n",
    "    \n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=doc_splits,\n",
    "        embedding=embd,\n",
    "        persist_path=persist_path,\n",
    "        serializer=\"parquet\"\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore.as_retriever(lambda_mult=0)\n",
    "'''\n",
    "\n",
    "utils_path = r\"C:\\Users\\Hunar Bhatia\\OneDrive\\Desktop\\MAT_494_Langchain\\Module_1\\utils.py\"\n",
    "with open(utils_path, 'w') as f:\n",
    "    f.write(utils_content)\n",
    "    \n",
    "print(\"✓ utils.py has been updated!\")\n",
    "with open(utils_path, 'r') as f:\n",
    "    content = f.read()\n",
    "    if 'RAG_PROMPT' in content:\n",
    "        print(\"✓ RAG_PROMPT found in utils.py\")\n",
    "    else:\n",
    "        print(\"✗ RAG_PROMPT NOT found in utils.py - File needs to be updated!\")\n",
    "    print(\"\\n--- File Contents ---\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "443ebdaf-843b-4b7a-b646-0c3381761cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Remove cached module\n",
    "if 'utils' in sys.modules:\n",
    "    del sys.modules['utils']\n",
    "\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "# Define RAG_PROMPT directly here\n",
    "RAG_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Now continue with your code\n",
    "retriever = get_vector_db_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3c0543e-eb2b-4e90-9d1a-f3506a8cf951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import tempfile\n",
      "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
      "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
      "from langchain_community.vectorstores import SKLearnVectorStore\n",
      "from langchain_openai import OpenAIEmbeddings\n",
      "\n",
      "# Define the RAG prompt template\n",
      "RAG_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Question: {question}\n",
      "\n",
      "Context: {context}\n",
      "\n",
      "Answer:\"\"\"\n",
      "\n",
      "def get_vector_db_retriever():\n",
      "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
      "    embd = OpenAIEmbeddings()\n",
      "\n",
      "    # If vector store exists, then load it\n",
      "    if os.path.exists(persist_path):\n",
      "        vectorstore = SKLearnVectorStore(\n",
      "            embedding=embd,\n",
      "            persist_path=persist_path,\n",
      "            serializer=\"parquet\"\n",
      "        )\n",
      "        return vectorstore.as_retriever(lambda_mult=0)\n",
      "\n",
      "    # Otherwise, index LangSmith documents and create new vector store\n",
      "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
      "    ls_docs = ls_docs_sitemap_loader.load()\n",
      "\n",
      "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
      "        chunk_size=500, chunk_overlap=0\n",
      "    )\n",
      "    doc_splits = text_splitter.split_documents(ls_docs)\n",
      "\n",
      "    vectorstore = SKLearnVectorStore.from_documents(\n",
      "        documents=doc_splits,\n",
      "        embedding=embd,\n",
      "        persist_path=persist_path,\n",
      "        serializer=\"parquet\"\n",
      "    )\n",
      "    vectorstore.persist()\n",
      "    return vectorstore.as_retriever(lambda_mult=0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Read and print the contents of utils.py\n",
    "utils_path = r\"C:\\Users\\Hunar Bhatia\\OneDrive\\Desktop\\MAT_494_Langchain\\Module_1\\utils.py\"\n",
    "\n",
    "with open(utils_path, 'r') as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5379583c-2cd4-469d-822c-9124e8db7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable, trace\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "# TODO: Remove traceable, and use with trace()\n",
    "def generate_response(question: str, documents):\n",
    "    # NOTE: Our documents came in as a list of objects, but we just want to log a string\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    # TODO: Use with trace()\n",
    "    with trace(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\", \n",
    "        inputs={\"question\": question, \"formatted_docs\": formatted_docs},\n",
    "        metadata={\"foo\": \"bar\"},\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": RAG_SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "            }\n",
    "        ]\n",
    "        response = call_openai(messages)\n",
    "        # TODO: End your trace and write outputs to LangSmith\n",
    "        ls_trace.end(outputs={\"output\": response})\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb93a2d0-4734-4c7b-bbc8-ce718763f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To trace with the tracing context in Python, you can use the `tracing_context` context manager from the LangSmith SDK. Wrap your code that you want to trace within the `with ls.tracing_context(enabled=True):` block, which will enable tracing for that specific invocation. If you want to disable tracing for certain parts, you can set `enabled=False` within another `tracing_context` block.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I trace with tracing context?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "254915cb-64c2-45d3-acce-acfbfa6d0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To trace with `wrap_openai`, you need to wrap your OpenAI client using the `wrap_openai` method, ensuring that the `LANGSMITH_TRACING` environment variable is set to 'true'. Additionally, set the `LANGSMITH_API_KEY` environment variable to your API key, and specify the workspace using `LANGSMITH_WORKSPACE_ID` if needed. This setup allows for automatic logging of traces, including messages and tool calls, without requiring additional decorators.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import wrap_openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "from langsmith import traceable\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Wrap the OpenAI Client\n",
    "openai_client = wrap_openai(openai.Client())\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    # TODO: We don't need to use @traceable on a nested function call anymore,\n",
    "    # wrap_openai takes care of this for us\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "question = \"How do I trace with wrap_openai?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffb43882-c596-47d6-a28a-58f370a21e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To trace with `wrap_openai`, you need to wrap your OpenAI client using the `wrap_openai` method from LangSmith's wrappers. First, ensure that the environment variable `LANGSMITH_TRACING` is set to 'true' and provide your LangSmith API key through the `LANGSMITH_API_KEY` environment variable. Then, you can call the OpenAI methods as usual, and the tracing information will be automatically logged without requiring additional decorators or function wrapping.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I trace with wrap_openai?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40468866-1c9b-46a7-8e2b-7404d3ff162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the color of the sky?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e39cba7-9955-4423-9ab4-150b6f2ca4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CMyAZ4T8VWfsriKpekN1koUbamEdg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The sky typically appears blue during the day due to Rayleigh scattering, where shorter wavelengths of light (blue) are scattered in all directions by the gases and particles in the Earth's atmosphere. However, the sky can also appear gray, white, orange, pink, or red at different times of day or in various weather conditions, such as during sunrise, sunset, or when there are clouds.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759590543, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=78, prompt_tokens=13, total_tokens=91, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What color is the sky?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    langsmith_extra={\"metadata\": {\"foo\": \"bar\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471bd787-be30-498a-9674-ad8ca36a6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca98025-0f3d-44b8-86db-10dfd69afb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# I have my env variables defined in a .env file\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48151385-131c-447c-aa71-98f5503e8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled() # This should return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca55cb3-d17c-4a56-9e1b-9ddb12dd464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "def retrieve_documents(parent_run: RunTree, question: str):\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Retrieve Documents\",\n",
    "        run_type=\"retriever\",\n",
    "        inputs={\"question\": question},\n",
    "    )\n",
    "    documents = retriever.invoke(question)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"documents\": documents})\n",
    "    child_run.post()\n",
    "    return documents\n",
    "\n",
    "def generate_response(parent_run: RunTree, question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"documents\": documents},\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rag_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    openai_response = call_openai(child_run, messages)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def call_openai(\n",
    "    parent_run: RunTree, messages: List[dict], model: str = \"gpt-4o-mini\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"OpenAI Call\",\n",
    "        run_type=\"llm\",\n",
    "        inputs={\"messages\": messages},\n",
    "    )\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    # Create a root RunTree\n",
    "    root_run_tree = RunTree(\n",
    "        name=\"Chat Pipeline\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question}\n",
    "    )\n",
    "\n",
    "    # Pass our RunTree into the nested function calls\n",
    "    documents = retrieve_documents(root_run_tree, question)\n",
    "    response = generate_response(root_run_tree, question, documents)\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Post our final output\n",
    "    root_run_tree.end(outputs={\"generation\": output})\n",
    "    root_run_tree.post()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce855579-8f7f-4994-882b-308e43557d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I trace with RunTree?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e103ef-2fe8-4f01-bcf0-979616483eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff5673-7fa3-4dac-9a94-203bfab51598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402b90b-3d50-4c5b-bbc3-748240a3abce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01736529-60ff-4bb1-abe3-351ba06d1932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
